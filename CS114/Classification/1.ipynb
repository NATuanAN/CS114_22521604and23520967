{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12136774,"sourceType":"datasetVersion","datasetId":7643204},{"sourceId":12236324,"sourceType":"datasetVersion","datasetId":7709891}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Classification","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.utils.data\nimport torch.utils.data as data_utils\nimport torchvision.transforms as transforms\nimport pickle as pkl\nimport pandas as pd\nimport torch\nimport torchvision\nfrom tqdm import tqdm\nfrom importlib import import_module\nimport shutil\nimport glob\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport logging\nfrom torch.nn.utils.rnn import pad_sequence\nimport pickle as pkl\nimport cv2\nimport logging\nimport math\nimport functools\nimport torch.nn as nn\nfrom torch.nn import init\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.nn import Parameter as P\n\nclass CustomDataset(data_utils.Dataset):\n \n    def __init__(self):\n  \n\n        with open(\"/kaggle/input/cs114-clss/data.pkl\", \"rb\") as f:\n            data = pkl.load(f)\n\n        self.word_data = data[\"word_data\"]\n        self.idx_to_id = {i: w_id for i, w_id in enumerate(self.word_data.keys())}\n        self.T = transforms.Compose(\n            [transforms.Resize(128)]\n        )\n        \n         \n    def __len__(self):\n        return len(self.word_data)\n\n    def __getitem__(self, idx):\n        item = {}\n        w_id = self.idx_to_id[idx]\n\n        # Get image and label\n        lab, img = self.word_data[w_id]\n\n        img = self.T(img)\n\n        item[\"img\"] = img.float()\n        item[\"label\"] = torch.tensor(lab)\n\n\n        return item\n\ndataset = CustomDataset()\n \n \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T15:37:24.526074Z","iopub.execute_input":"2025-06-25T15:37:24.526731Z","iopub.status.idle":"2025-06-25T15:37:25.742503Z","shell.execute_reply.started":"2025-06-25T15:37:24.526708Z","shell.execute_reply":"2025-06-25T15:37:25.741873Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"from torch.utils.data import random_split\n \ntotal_size = len(dataset)\ntrain_size = int(0.8 * total_size)\ntest_size = total_size - train_size\n\ntrain_set, test_set = random_split(dataset, [train_size, test_size])\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T15:37:27.050984Z","iopub.execute_input":"2025-06-25T15:37:27.051548Z","iopub.status.idle":"2025-06-25T15:37:27.083349Z","shell.execute_reply.started":"2025-06-25T15:37:27.051525Z","shell.execute_reply":"2025-06-25T15:37:27.082742Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def imshow(inp, title=None):   \n    inp = inp.numpy()\n \n    inp = np.transpose(inp, (1, 2, 0))\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n\n    if title is not None:\n        plt.title(title)\n    plt.axis('off')\n    plt.show()\n\n\nbatch = next(iter(train_loader))\ninputs = batch[\"img\"]\nclasses = batch[\"label\"]\n \nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[int(x) for x in classes])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T15:37:28.127273Z","iopub.execute_input":"2025-06-25T15:37:28.128008Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/528412585.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item[\"label\"] = torch.tensor(lab)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nfrom PIL import Image\nfrom tempfile import TemporaryDirectory\n\ncudnn.benchmark = True\nplt.ion()   # interactive mode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T15:36:18.346199Z","iopub.execute_input":"2025-06-25T15:36:18.346460Z","iopub.status.idle":"2025-06-25T15:36:18.352687Z","shell.execute_reply.started":"2025-06-25T15:36:18.346441Z","shell.execute_reply":"2025-06-25T15:36:18.351976Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"<contextlib.ExitStack at 0x7a0b9652f190>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"device = \"cuda\"\nmodel_ft = models.resnet18(weights='IMAGENET1K_V1')\nnum_ftrs = model_ft.fc.in_features\n# Here the size of each output sample is set to 2.\n# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\nmodel_ft.fc = nn.Linear(num_ftrs, 10)\n\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T15:37:31.723372Z","iopub.execute_input":"2025-06-25T15:37:31.724069Z","iopub.status.idle":"2025-06-25T15:37:31.940073Z","shell.execute_reply.started":"2025-06-25T15:37:31.724043Z","shell.execute_reply":"2025-06-25T15:37:31.939470Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"from tqdm import tqdm\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    # Create a temporary directory to save training checkpoints\n    with TemporaryDirectory() as tempdir:\n        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n\n        torch.save(model.state_dict(), best_model_params_path)\n        best_acc = 0.0\n        best_loss = 999\n        cnt_stop = 0\n        for epoch in range(num_epochs):\n            print(f'Epoch {epoch}/{num_epochs - 1}')\n            print('-' * 10)\n\n            # Each epoch has a training and validation phase\n            for phase in ['train']:\n                if phase == 'train':\n                    model.train()  # Set model to training mode\n                else:\n                    model.eval()   # Set model to evaluate mode\n\n                running_loss = 0.0\n                running_corrects = 0\n\n                # Iterate over data.\n                for batch in tqdm(train_loader):\n                    inputs = batch[\"img\"].to(device)\n                    labels = batch[\"label\"].to(device)\n\n                    # zero the parameter gradients\n                    optimizer.zero_grad()\n\n                    # forward\n                    # track history if only in train\n                    with torch.set_grad_enabled(phase == 'train'):\n                        outputs = model(inputs)\n                        _, preds = torch.max(outputs, 1)\n                        loss = criterion(outputs, labels)\n\n                        # backward + optimize only if in training phase\n                        if phase == 'train':\n                            loss.backward()\n                            optimizer.step()\n\n                    # statistics\n                    running_loss += loss.item()\n     \n                if phase == 'train':\n                    scheduler.step()\n\n                epoch_loss = running_loss / len(train_loader)\n                if epoch_loss < best_loss:\n                    torch.save(model.state_dict(), best_model_params_path)\n                    best_loss = epoch_loss\n                    cnt_stop = 0\n                else:\n                    cnt_stop += 1\n                if cnt_stop>=5:\n                    torch.save(model.state_dict(), best_model_params_path)\n                    return model\n\n                print(f'{phase} Loss: {epoch_loss:.4f}')\n\n              \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T15:37:33.018777Z","iopub.execute_input":"2025-06-25T15:37:33.019332Z","iopub.status.idle":"2025-06-25T15:37:33.027332Z","shell.execute_reply.started":"2025-06-25T15:37:33.019305Z","shell.execute_reply":"2025-06-25T15:37:33.026546Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T15:37:35.255587Z","iopub.execute_input":"2025-06-25T15:37:35.256117Z","iopub.status.idle":"2025-06-25T15:38:59.741659Z","shell.execute_reply.started":"2025-06-25T15:37:35.256091Z","shell.execute_reply":"2025-06-25T15:38:59.741110Z"}},"outputs":[{"name":"stdout","text":"Epoch 0/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/80 [00:00<?, ?it/s]/tmp/ipykernel_35/528412585.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item[\"label\"] = torch.tensor(lab)\n100%|██████████| 80/80 [00:06<00:00, 13.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 1.7969\nEpoch 1/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 19.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.7239\nEpoch 2/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.3594\nEpoch 3/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.2212\nEpoch 4/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1475\nEpoch 5/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1070\nEpoch 6/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0833\nEpoch 7/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0665\nEpoch 8/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0630\nEpoch 9/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0639\nEpoch 10/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0592\nEpoch 11/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0620\nEpoch 12/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0590\nEpoch 13/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0572\nEpoch 14/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0585\nEpoch 15/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0602\nEpoch 16/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0592\nEpoch 17/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.0578\nEpoch 18/49\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 80/80 [00:04<00:00, 18.91it/s]\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"all_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in tqdm(test_loader):\n        inputs = batch[\"img\"].to(device)\n        labels = batch[\"label\"].to(device)\n        \n        outputs =model_ft(inputs)\n        _, preds = torch.max(outputs, 1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T15:39:02.035794Z","iopub.execute_input":"2025-06-25T15:39:02.036085Z","iopub.status.idle":"2025-06-25T15:39:02.796006Z","shell.execute_reply.started":"2025-06-25T15:39:02.036065Z","shell.execute_reply":"2025-06-25T15:39:02.795359Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/20 [00:00<?, ?it/s]/tmp/ipykernel_35/528412585.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item[\"label\"] = torch.tensor(lab)\n100%|██████████| 20/20 [00:00<00:00, 26.60it/s]\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\nprint(\"Test Accuracy:\", accuracy_score(all_labels, all_preds))\nprint(classification_report(all_labels, all_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T15:39:04.403623Z","iopub.execute_input":"2025-06-25T15:39:04.404315Z","iopub.status.idle":"2025-06-25T15:39:04.416983Z","shell.execute_reply.started":"2025-06-25T15:39:04.404291Z","shell.execute_reply":"2025-06-25T15:39:04.416288Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.9173228346456693\n              precision    recall  f1-score   support\n\n           0       0.92      0.96      0.94       119\n           1       0.90      0.94      0.92       108\n           2       0.92      0.92      0.92       129\n           3       0.91      0.87      0.89       146\n           4       0.90      0.91      0.91       126\n           5       0.94      0.91      0.92       129\n           6       0.98      0.95      0.96       133\n           7       0.89      0.91      0.90       136\n           8       0.92      0.94      0.93       121\n           9       0.91      0.88      0.89       123\n\n    accuracy                           0.92      1270\n   macro avg       0.92      0.92      0.92      1270\nweighted avg       0.92      0.92      0.92      1270\n\n","output_type":"stream"}],"execution_count":37}]}